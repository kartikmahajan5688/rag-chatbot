# ğŸ“š AI Document Chatbot (RAG + Pinecone + OpenAI)

**Chat with your documents intelligently using Retrieval-Augmented Generation (RAG) powered by OpenAI, Pinecone, and FastAPI â€” with a beautiful Gradio UI.**

---

## ğŸš€ Features

âœ… Upload and process **PDF or Text** documents
âœ… Automatically **index content into Pinecone Vector Database**
âœ… Chat with your document using **OpenAI GPT model (RAG pipeline)**
âœ… **FastAPI backend** + **Gradio frontend** for easy deployment
âœ… Supports **conversation memory** for contextual chatting
âœ… Modular code for **scalable multi-document support**

---

## ğŸ§  Tech Stack

| Component           | Technology                                                     |
| ------------------- | -------------------------------------------------------------- |
| ğŸ’¬ LLM              | [OpenAI GPT (via LangChain)](https://platform.openai.com/docs) |
| ğŸ§© Vector Store     | [Pinecone](https://www.pinecone.io/)                           |
| âš™ï¸ Framework        | [FastAPI](https://fastapi.tiangolo.com/)                       |
| ğŸ§± Frontend         | [Gradio](https://www.gradio.app/)                              |
| ğŸ§° Embeddings       | [LangChain OpenAIEmbeddings](https://python.langchain.com/)    |
| ğŸ“„ Document Loaders | LangChain Community Loaders                                    |
| â˜ï¸ Deployment       | Uvicorn (ASGI Server)                                          |

---

## ğŸ“‚ Project Structure

```
ğŸ“ ai-document-chatbot/
â”‚
â”œâ”€â”€ app.py                  # Main FastAPI + Gradio application
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ .env                    # Environment variables (not committed)
â””â”€â”€ documents/              # Your sample or uploaded documents
```

---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/kartikmahajan5688/rag-chatbot.git
cd ai-document-chatbot
```

### 2ï¸âƒ£ Create a Virtual Environment

```bash
python -m venv venv
source venv/bin/activate   # On macOS/Linux
venv\Scripts\activate      # On Windows
```

### 3ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Create a `.env` File

Inside the project root, create a `.env` file and add your API keys:

```bash
OPENAI_API_KEY=your_openai_api_key
PINECONE_API_KEY=your_pinecone_api_key
PINECONE_INDEX_NAME=rag-index
```

> ğŸ§  Make sure your Pinecone project is **serverless** and uses the same region as specified in the code (`us-east-1`).

---

## ğŸ§¾ Document Ingestion (Optional Step)

Before chatting, you can pre-load some documents manually using `main.py`.

```bash
python main.py
```

This will:

- Load PDFs or text files from the `./documents/` directory
- Split text into chunks
- Create embeddings using OpenAI
- Store them in Pinecone

---

## ğŸ’¬ Run the Chatbot App

Start the FastAPI + Gradio interface:

```bash
python app.py
```

Once running, visit:

```
http://localhost:8000/gradio
```

Youâ€™ll see a beautiful Gradio UI like this:

```
ğŸ“˜ Upload your document and chat with it using AI!
```

1. Upload a PDF or Text file
2. Wait for it to process and index
3. Start chatting â€” ask natural language questions about your document!

---

## ğŸŒ API Access (Optional)

The FastAPI server is available under the same app.
If you deploy it (e.g., to Render or Railway), the Gradio UI mounts at `/gradio`.

---

## ğŸ§© Example Workflow

1. Upload a file like `company-policy.pdf`
2. The system:

   - Splits text into chunks
   - Creates embeddings
   - Stores in Pinecone
   - Enables semantic search retrieval

3. Chat:

   ```
   ğŸ‘¤ User: What is the companyâ€™s leave policy?
   ğŸ¤– Bot: The company allows 24 paid leaves per year, as stated in section 3.2 of the document.
   ```

---

## ğŸ§  How It Works (Architecture)

```mermaid
flowchart TD
A[User Uploads Document] --> B[LangChain Loaders]
B --> C[Text Splitter (Chunks)]
C --> D[OpenAI Embeddings]
D --> E[Pinecone Vector Store]
E --> F[ConversationalRetrievalChain]
F --> G[ChatOpenAI (GPT)]
G --> H[Response via Gradio UI]
```

---

## ğŸ§° Requirements

| Library             | Version |
| ------------------- | ------- |
| fastapi             | latest  |
| uvicorn[standard]   | latest  |
| gradio              | latest  |
| python-dotenv       | latest  |
| pinecone-client     | latest  |
| langchain           | latest  |
| langchain-openai    | latest  |
| langchain-pinecone  | latest  |
| langchain-community | latest  |
| pypdf               | latest  |
| tiktoken            | latest  |

_(All managed via `requirements.txt`)_

---

## ğŸš€ Deployment Tips

- For **local use**, just run `python app.py`.
- To **deploy on Render / Railway / HuggingFace Spaces**, set:

  ```
  START_CMD = python app.py
  PORT = 8000
  ```

- Ensure environment variables (`.env`) are configured in the platform.

---

## ğŸ§‘â€ğŸ’» Author

**ğŸ‘‹ Developed by:** _[Kartik Mahajan]_
ğŸ“§ Email: [kartikmahajan5688@gmail.com](mailto:kartikmahajan5688@gmail.com)

---

## ğŸªª License

This project is licensed under the **MIT License** â€“ feel free to use, modify, and share!

---

## ğŸ’– Support

If you found this project helpful, please â­ the repository and share it with others!
Letâ€™s build smarter AI assistants together ğŸš€

---
